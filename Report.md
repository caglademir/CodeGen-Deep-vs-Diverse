
ğŸ“‘ CodeGen Projesi: DÃ¼ÅŸÃ¼nce Zinciri (CoT) Modelleri Performans Analiz Raporu
 
1. YÃ¶netici Ã–zeti (Executive Summary)
Bu proje kapsamÄ±nda, Qwen2.5-Coder-1.5B-Instruct taban modeli, proje dÃ¶kÃ¼mantasyonunda belirtilen yÃ¶nergelere tam sadakatle baÄŸlÄ± kalÄ±narak iki farklÄ± strateji ile eÄŸitilmiÅŸtir: Deep Think ve Diverse Think.
Ã‡alÄ±ÅŸmanÄ±n temel amacÄ±, veri setlerinde yer alan "Output" (Ã‡Ä±ktÄ±) kÄ±sÄ±mlarÄ±ndaki farklÄ± dÃ¼ÅŸÃ¼nce yapÄ±larÄ±nÄ±n (derinlemesine mantÄ±k vs. Ã§eÅŸitli bakÄ±ÅŸ aÃ§Ä±larÄ±) modelin kod Ã¼retim baÅŸarÄ±sÄ±na etkisini Ã¶lÃ§mektir. YapÄ±lan LiveCodeBench (AtCoder-Easy) testleri sonucunda; Deep Think yaklaÅŸÄ±mÄ±nÄ±n, modelin karmaÅŸÄ±k problemleri Ã§Ã¶zme yeteneÄŸini daha hÄ±zlÄ± geliÅŸtirdiÄŸi ve %26.83 ile en yÃ¼ksek baÅŸarÄ± oranÄ±na ulaÅŸtÄ±ÄŸÄ± tespit edilmiÅŸtir.
 

2. Veri Seti ve EÄŸitim Metodolojisi
EÄŸitim sÃ¼reci, saÄŸlanan teknik dÃ¶kÃ¼mandaki parametreler ve veri iÅŸleme talimatlarÄ± doÄŸrultusunda gerÃ§ekleÅŸtirilmiÅŸtir.
2.1. Veri Seti KullanÄ±mÄ± (Dataset Utilization)
Modellerin eÄŸitiminde, sadece problem tanÄ±mlarÄ± (input) deÄŸil, veri setlerinin Output (Ã‡Ä±ktÄ±) sÃ¼tunlarÄ±nda yer alan "Reasoning Traces" (MantÄ±k YÃ¼rÃ¼tme Ä°zleri) aktif olarak kullanÄ±lmÄ±ÅŸtÄ±r:
â€¢	Deep Think Modeli: Naholav/CodeGen-Deep-5K veri seti kullanÄ±lmÄ±ÅŸtÄ±r. Bu veri setinin outputkÄ±sÄ±mlarÄ±nda yer alan uzun, adÄ±m adÄ±m ve detaylandÄ±rÄ±lmÄ±ÅŸ Ã§Ã¶zÃ¼m yollarÄ± modele Ã¶ÄŸretilerek, modelin bir problemi Ã§Ã¶zerken "derinlemesine dÃ¼ÅŸÃ¼nmesi" hedeflenmiÅŸtir.
â€¢	Diverse Think Modeli: Naholav/CodeGen-Diverse-5K veri seti kullanÄ±lmÄ±ÅŸtÄ±r. Bu setin outputkÄ±sÄ±mlarÄ±ndaki aynÄ± probleme getirilmiÅŸ farklÄ± ve Ã§eÅŸitli Ã§Ã¶zÃ¼m yaklaÅŸÄ±mlarÄ± modele Ã¶ÄŸretilerek, modelin bakÄ±ÅŸ aÃ§Ä±sÄ± zenginleÅŸtirilmeye Ã§alÄ±ÅŸÄ±lmÄ±ÅŸtÄ±r.
2.2. DÃ¶kÃ¼mana Uyumluluk (Adherence to Documentation)
Proje dÃ¶kÃ¼manÄ±nda belirtilen aÅŸaÄŸÄ±daki kÄ±sÄ±tlar ve parametreler deÄŸiÅŸtirilmeden uygulanmÄ±ÅŸtÄ±r:
â€¢	Taban Model: Qwen/Qwen2.5-Coder-1.5B-Instruct
â€¢	EÄŸitim SÃ¼resi: Her model iÃ§in yaklaÅŸÄ±k 3 Epoch (800 Step).
â€¢	DeÄŸerlendirme: LiveCodeBench framework'Ã¼ Ã¼zerinden, 2408-2502 tarih aralÄ±ÄŸÄ±ndaki AtCoder (Easy) problemleri.
â€¢	Metrik: Pass@1 (Tek seferde doÄŸru Ã§Ã¶zÃ¼m oranÄ±).
 
3. EÄŸitim Dinamikleri ve KayÄ±p (Loss) Analizi
Modellerin Ã¶ÄŸrenme sÃ¼recinin kararlÄ±lÄ±ÄŸÄ±nÄ± (stability) ve yakÄ±nsama hÄ±zÄ±nÄ± (convergence speed) deÄŸerlendirmek amacÄ±yla, 800 adÄ±mlÄ±k eÄŸitim sÃ¼reci boyunca kaydedilen "Training Loss" deÄŸerleri analiz edilmiÅŸtir. EÄŸitim kaybÄ±nÄ±n dÃ¼ÅŸÃ¼ÅŸ eÄŸilimi, modelin veri setindeki mantÄ±ksal yapÄ±larÄ± ne kadar baÅŸarÄ±lÄ± bir ÅŸekilde iÃ§selleÅŸtirdiÄŸinin birincil gÃ¶stergesidir.
3.1. EÄŸitim KayÄ±p GrafiÄŸi
AÅŸaÄŸÄ±daki grafik, Deep Think ve Diverse Think modellerinin eÄŸitim adÄ±mlarÄ±na (steps) gÃ¶re loss deÄŸiÅŸimini gÃ¶stermektedir:
 
 

3.2. Grafik Yorumu ve GÃ¶zlemler
Grafik ve log kayÄ±tlarÄ± incelendiÄŸinde ÅŸu temel Ã§Ä±karÄ±mlar yapÄ±lmÄ±ÅŸtÄ±r:
â€¢	HÄ±zlÄ± Adaptasyon (Early Convergence): Her iki modelde de ilk 100 adÄ±mda loss deÄŸerinde keskin bir dÃ¼ÅŸÃ¼ÅŸ gÃ¶zlemlenmiÅŸtir. Bu durum, Qwen2.5 taban modelinin, yeni veri setlerine (Deep ve Diverse instruction formatlarÄ±na) hÄ±zla uyum saÄŸladÄ±ÄŸÄ±nÄ± gÃ¶stermektedir.
â€¢	Deep Think Ä°stikrarÄ±: Deep Think modelinin loss eÄŸrisi, daha pÃ¼rÃ¼zsÃ¼z ve istikrarlÄ± bir dÃ¼ÅŸÃ¼ÅŸ sergilemiÅŸtir. Modelin "AdÄ±m AdÄ±m DÃ¼ÅŸÃ¼nme" (CoT) yapÄ±sÄ±nÄ± Ã¶ÄŸrenmesi, optimizasyon aÃ§Ä±sÄ±ndan daha verimli gerÃ§ekleÅŸmiÅŸtir.
â€¢	Diverse Think DalgalanmalarÄ±: Diverse Think modelinin loss grafiÄŸinde yer yer (Ã¶zellikle orta adÄ±mlarda) kÃ¼Ã§Ã¼k dalgalanmalar veya daha yavaÅŸ bir dÃ¼ÅŸÃ¼ÅŸ gÃ¶rÃ¼lmÃ¼ÅŸtÃ¼r. Bu durum, veri setindeki "Ã§eÅŸitli Ã§Ã¶zÃ¼m yollarÄ±nÄ±n" (diversity) model tarafÄ±ndan genelleÅŸtirilmesinin daha zorlu bir sÃ¼reÃ§ olduÄŸunu, ancak modelin eÄŸitimin sonunda (Step 800) baÅŸarÄ±lÄ± bir minima noktasÄ±na ulaÅŸtÄ±ÄŸÄ±nÄ± kanÄ±tlamaktadÄ±r.
â€¢	AÅŸÄ±rÄ± Ã–ÄŸrenme KontrolÃ¼: Step 400 civarÄ±nda loss deÄŸerinin optimum seviyeye yaklaÅŸtÄ±ÄŸÄ± gÃ¶rÃ¼lmÃ¼ÅŸtÃ¼r. Bu nokta, Benchmark testlerindeki zirve performans (Step 400: %26.83) ile de Ã¶rtÃ¼ÅŸmektedir. Step 500 sonrasÄ±nda loss deÄŸerinde marjinal dÃ¼ÅŸÃ¼ÅŸler devam etse de, validasyon baÅŸarÄ±sÄ±ndaki dalgalanmalar modelin ezberlemeye (overfitting) yatkÄ±n hale geldiÄŸine iÅŸaret etmektedir.
 4. Deneysel SonuÃ§lar (Experimental Results)
AÅŸaÄŸÄ±daki tablo, modellerin eÄŸitim sÃ¼reci boyunca gÃ¶sterdiÄŸi performansÄ± karÅŸÄ±laÅŸtÄ±rmaktadÄ±r. Veriler, her 100 adÄ±mda bir alÄ±nan checkpoint'lerin benchmark sonuÃ§larÄ±ndan derlenmiÅŸtir.
Checkpoint (Step)	Epoch	Deep Think Pass@1	Diverse Think Pass@1	Fark (Deep vs Diverse)
Step 100	0.35	%17.1	%9.8	Deep (+%7.3)
Step 200	0.71	%24.4	%24.4	EÅŸit
Step 300	1.06	%17.1	%14.6	Deep (+%2.5)
Step 400	1.42	%26.8 ğŸ¥‡	%22.0	Deep (+%4.8)
Step 500	1.77	%12.2	%12.2	EÅŸit
Step 600	2.13	%22.0	%22.0	EÅŸit
Step 700	2.48	%12.2	%12.2	EÅŸit
Step 800	2.84	%24.4	%24.4	EÅŸit


 
5. Analiz ve Bulgular
5.1. Output Verisinin Etkisi
Veri setlerindeki output yapÄ±larÄ±nÄ±n farkÄ±, modellerin Ã¶ÄŸrenme eÄŸrisini (learning curve) doÄŸrudan etkilemiÅŸtir:
â€¢	Deep Think'in Output YapÄ±sÄ±: AdÄ±m adÄ±m ilerleyen mantÄ±ksal Ã§Ã¶zÃ¼m yapÄ±sÄ± (Deep output), modelin henÃ¼z eÄŸitimin baÅŸÄ±nda (Step 100) %7.3'lÃ¼k bir fark atmasÄ±nÄ± saÄŸlamÄ±ÅŸtÄ±r. Bu, modelin "nasÄ±l dÃ¼ÅŸÃ¼neceÄŸini" daha hÄ±zlÄ± Ã¶ÄŸrendiÄŸini gÃ¶sterir.
â€¢	Diverse Think'in Output YapÄ±sÄ±: Ã‡eÅŸitlilik iÃ§eren outputlar, modelin baÅŸta kararsÄ±z kalmasÄ±na (Step 100: %9.8) neden olmuÅŸ, ancak eÄŸitimin sonlarÄ±na doÄŸru model bu Ã§eÅŸitliliÄŸi Ã¶zÃ¼mseyerek Deep Think ile aynÄ± seviyeye gelmiÅŸtir.
5.2. En Ä°yi Model SeÃ§imi
Proje dÃ¶kÃ¼manÄ±ndaki baÅŸarÄ± kriterleri gÃ¶z Ã¶nÃ¼ne alÄ±ndÄ±ÄŸÄ±nda; Step 400 (Epoch 1.42) noktasÄ±ndaki Deep Think modeli, %26.83 baÅŸarÄ± oranÄ± ile en optimum model olarak belirlenmiÅŸtir. 
 

 
6. DetaylÄ± Analiz ve TartÄ±ÅŸma (Discussion & Insights)
Bu bÃ¶lÃ¼mde, elde edilen deneysel bulgular; model mimarisi, veri yapÄ±sÄ± ve eÄŸitim dinamikleri perspektifinden yorumlanmÄ±ÅŸ, "Deep" ve "Diverse" stratejilerinin altÄ±nda yatan neden-sonuÃ§ iliÅŸkileri irdelenmiÅŸtir.
6.1. BiliÅŸsel YÃ¼k ve Ã–ÄŸrenme VerimliliÄŸi Hipotezi
Deneysel sonuÃ§lar, Deep Think (Derinlemesine DÃ¼ÅŸÃ¼nme) stratejisinin modele daha hÄ±zlÄ± ve keskin bir yetenek kazandÄ±rdÄ±ÄŸÄ±nÄ± gÃ¶stermektedir.
â€¢	Bulgu: Deep Think, Step 100'de %17.1 gibi yÃ¼ksek bir baÅŸlangÄ±Ã§ yapmÄ±ÅŸ ve 400. adÄ±mda zirveye ulaÅŸmÄ±ÅŸtÄ±r.
â€¢	Analiz: 1.5 milyar parametreli (1.5B) gibi nispeten "kÃ¼Ã§Ã¼k" sayÄ±lan LLM'lerde, modelin kapasitesi sÄ±nÄ±rlÄ±dÄ±r. Deep Think veri setindeki "tekil ama derinlemesine aÃ§Ä±klanmÄ±ÅŸ" Ã§Ã¶zÃ¼m yolu, modelin Ã¼zerindeki biliÅŸsel yÃ¼kÃ¼ (cognitive load) azaltmÄ±ÅŸtÄ±r. Model, bir problemi Ã§Ã¶zmek iÃ§in net bir "algoritmik rota" izlemeyi Ã¶ÄŸrenmiÅŸ ve bu da optimizasyon sÃ¼recini hÄ±zlandÄ±rmÄ±ÅŸtÄ±r.
â€¢	Diverse Think Durumu: Buna karÅŸÄ±n, Diverse Think setindeki "Ã§oklu Ã§Ã¶zÃ¼m yollarÄ±", 1.5B boyutundaki bir modelde baÅŸlangÄ±Ã§ta kafa karÄ±ÅŸÄ±klÄ±ÄŸÄ±na (ambiguity) yol aÃ§mÄ±ÅŸ olabilir. Modelin hangi Ã§Ã¶zÃ¼m stratejisini aÄŸÄ±rlÄ±klandÄ±racaÄŸÄ±na karar vermesi zaman almÄ±ÅŸ, bu da Ã¶ÄŸrenme eÄŸrisinin (learning curve) daha yatay seyretmesine neden olmuÅŸtur.
6.2. Kapasite DoygunluÄŸu ve "Unutma" (Catastrophic Forgetting) Riski
Her iki modelde de Step 400-500 sonrasÄ±nda gÃ¶zlemlenen dalgalanmalar ve performans dÃ¼ÅŸÃ¼ÅŸleri kritik bir teknik detaya iÅŸaret etmektedir.
â€¢	GÃ¶zlem: Step 400'deki %26.8'lik zirve baÅŸarÄ±, eÄŸitim devam ettikÃ§e korunamamÄ±ÅŸ ve Step 500'de %12.2'ye gerilemiÅŸtir.
â€¢	Yorum: Bu durum, modelin "Overfitting" (AÅŸÄ±rÄ± Ã–ÄŸrenme) sÄ±nÄ±rÄ±na geldiÄŸini ve eÄŸitim verisindeki gÃ¼rÃ¼ltÃ¼yÃ¼ ezberlemeye baÅŸladÄ±ÄŸÄ±nÄ± dÃ¼ÅŸÃ¼ndÃ¼rmektedir. AyrÄ±ca, 1.5B modelin parametre uzayÄ±nÄ±n doygunluÄŸa ulaÅŸtÄ±ÄŸÄ±, yeni karmaÅŸÄ±k desenleri Ã¶ÄŸrenmeye Ã§alÄ±ÅŸÄ±rken daha Ã¶nce Ã¶ÄŸrendiÄŸi temel yetenekleri baskÄ±ladÄ±ÄŸÄ± (Catastrophic Forgetting) sonucuna varÄ±labilir.
6.3. "Diverse" Verinin Uzun Vadeli Etkisi
Diverse Think stratejisinin baÅŸarÄ±sÄ±z olduÄŸu sÃ¶ylenemez; aksine, eÄŸitimin sonunda Deep Think ile performansÄ±nÄ±n eÅŸitlenmesi (Convergence) Ã¶nemli bir bulgudur.
â€¢	Analiz: Bu, yeterli eÄŸitim sÃ¼resi (epoch) verildiÄŸinde, modelin "Ã§eÅŸitlilikten" gelen karmaÅŸayÄ± Ã§Ã¶zebildiÄŸini ve bu Ã§eÅŸitliliÄŸi genel bir kodlama yeteneÄŸine dÃ¶nÃ¼ÅŸtÃ¼rebildiÄŸini gÃ¶sterir. Ancak, bu projedeki gibi sÄ±nÄ±rlÄ± kaynak ve adÄ±m sayÄ±sÄ±nda (800 step), Diverse stratejisi "maliyet/performans" aÃ§Ä±sÄ±ndan Deep stratejisinin gerisinde kalmÄ±ÅŸtÄ±r.
6.4. Gelecek Ã‡alÄ±ÅŸmalar ve Stratejik Ã–neriler (Future Work)
Bu Ã§alÄ±ÅŸmadan elde edilen iÃ§gÃ¶rÃ¼ler doÄŸrultusunda, bir sonraki aÅŸamada ÅŸu stratejilerin uygulanmasÄ± Ã¶nerilmektedir:
1.	Hibrit EÄŸitim (Curriculum Learning): EÄŸitime Ã¶nce Deep Think verisi ile baÅŸlanÄ±p, modelin temel mantÄ±k yÃ¼rÃ¼tme yeteneÄŸi oturtulduktan sonra (Ã¶rneÄŸin 400. adÄ±mdan sonra), Diverse Think verisi ile devam edilerek modelin esnekliÄŸi artÄ±rÄ±labilir.
2.	Erken Durdurma (Early Stopping): Step 400'den sonra performansÄ±n plato Ã§izmesi veya dÃ¼ÅŸmesi nedeniyle, kaynak verimliliÄŸi iÃ§in eÄŸitimin bu noktada kesilmesi (Early Stopping) en optimal stratejidir.
3.	Model Ã–lÃ§ekleme: Diverse Think stratejisinin potansiyelini tam olarak gÃ¶rebilmek iÃ§in, parametre kapasitesi daha yÃ¼ksek (Ã¶rneÄŸin Qwen2.5-7B veya 14B) modeller Ã¼zerinde test edilmesi, modelin farklÄ± bakÄ±ÅŸ aÃ§Ä±larÄ±nÄ± daha iyi sentezlemesini saÄŸlayabilir.
 
7. SonuÃ§
Bu Ã§alÄ±ÅŸma, LLM eÄŸitiminde kullanÄ±lan veri setinin sadece input deÄŸil, output kalitesinin ve yapÄ±sÄ±nÄ±n da performansÄ± kritik dÃ¼zeyde etkilediÄŸini doÄŸrulamÄ±ÅŸtÄ±r. Proje dÃ¶kÃ¼manÄ±ndaki yÃ¶nergelere sadÄ±k kalÄ±narak yapÄ±lan testlerde, derinlemesine dÃ¼ÅŸÃ¼nme (Deep Think) stratejisinin, kodlama problemlerinde daha hÄ±zlÄ± ve yÃ¼ksek baÅŸarÄ± saÄŸladÄ±ÄŸÄ± sonucuna varÄ±lmÄ±ÅŸtÄ±r.
Model	En Ä°yi Checkpoint	Pass@1	Ã‡Ã¶zÃ¼len Soru
Base Model	-	%	27/41
Deep_instruction	step-400	%26.83 ğŸ¥‡	11/41 ğŸ¥‡
Diverse_instruction	step-200	%24.39	10/41

 

