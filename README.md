
ğŸ§  Reasoning-Enhanced LLM: Comparative Analysis of Deep vs. Diverse Instruction Tuning
ğŸ“‘ Proje Ã–zeti (Executive Summary)
Bu proje, Large Language Models (LLMs) dÃ¼nyasÄ±nda "Reasoning" (AkÄ±l YÃ¼rÃ¼tme) yeteneÄŸinin Supervised Fine-Tuning (SFT) yÃ¶ntemiyle nasÄ±l kazandÄ±rÄ±lacaÄŸÄ±nÄ± araÅŸtÄ±rmaktadÄ±r.
Proje kapsamÄ±nda, Qwen2.5-Coder-1.5B-Instruct temel modeli, iki farklÄ± veri seti stratejisi ("Deep" ve "Diverse") kullanÄ±larak LoRA (Low-Rank Adaptation) yÃ¶ntemiyle eÄŸitilmiÅŸtir. AmaÃ§, modelin sadece kod sentaksÄ±nÄ± Ã¶ÄŸrenmesi deÄŸil, Chain-of-Thought (CoT) yaklaÅŸÄ±mÄ±yla problemleri adÄ±m adÄ±m analiz ederek Ã§Ã¶zmesidir.
ğŸ”¬ Metodoloji ve Veri Setleri
Projede hipotez testi iÃ§in iki farklÄ± eÄŸitim stratejisi kurgulanmÄ±ÅŸtÄ±r:
Strateji	Veri Seti YapÄ±sÄ±	Hedeflenen Yetkinlik
ğŸ”µ Deep Instruction	KarmaÅŸÄ±k, Ã§ok adÄ±mlÄ± mantÄ±k zincirleri iÃ§eren derinlemesine problemler.	Zor problemlerde derinlemesine mantÄ±k yÃ¼rÃ¼tme (Deep Reasoning).
ğŸŸ£ Diverse Instruction	FarklÄ± alanlara yayÄ±lmÄ±ÅŸ, geniÅŸ Ã§eÅŸitlilikte problem tipleri.	HÄ±zlÄ± adaptasyon, genelleme (Generalization) ve veri verimliliÄŸi.
ğŸš€ Kritik EÄŸitim Stratejisi: "Output" (Reasoning + Code) KullanÄ±mÄ±
Bu Ã§alÄ±ÅŸmada standart "Instruction -> Solution" eÄŸitimi yerine, veri setindeki opsiyonel Output (Reasoning Steps + Code) alanÄ± aktif olarak kullanÄ±lmÄ±ÅŸtÄ±r.
â€¢	AmaÃ§: Modele sadece nihai kodu deÄŸil, o koda giden dÃ¼ÅŸÃ¼nce sÃ¼recini (Thinking Process)Ã¶ÄŸretmek.
â€¢	YÃ¶ntem: Model, problemleri Ã§Ã¶zerken <think> etiketleri arasÄ±nda adÄ±m adÄ±m mantÄ±k yÃ¼rÃ¼tmeye teÅŸvik edilmiÅŸtir.
âš™ï¸ Teknik KonfigÃ¼rasyon ve Hiperparametreler
EÄŸitim sÃ¼recinde "Long Context" yeteneklerini korumak ve hassas Ã¶ÄŸrenme saÄŸlamak adÄ±na aÅŸaÄŸÄ±daki konfigÃ¼rasyon kullanÄ±lmÄ±ÅŸtÄ±r:
ğŸ› ï¸ Model & LoRA AyarlarÄ±
â€¢	Base Model: Qwen/Qwen2.5-Coder-1.5B-Instruct
â€¢	LoRA Rank (r): 16
â€¢	LoRA Alpha: 32
â€¢	Target Modules: q_proj, k_proj, v_proj, o_proj, gate_proj, up_proj, down_proj
â€¢	LoRA Dropout: 0.05
ğŸ“‰ EÄŸitim Parametreleri
â€¢	Epoch SayÄ±sÄ±: 3 (Tam EÄŸitim DÃ¶ngÃ¼sÃ¼)
â€¢	Learning Rate: 5e-5 (Hassas ayar iÃ§in dÃ¼ÅŸÃ¼k tutuldu)
â€¢	Context Length: 8192 Token (Uzun mantÄ±k zincirlerini desteklemek iÃ§in geniÅŸletildi)
â€¢	Effective Batch Size: 16 (Gradient Accumulation ile)
â€¢	Precision: float16 (T4 Optimization) / bfloat16 (A100)
â€¢	System Prompt: "You are an expert Python programmer. Please read the problem carefully before writing any Python code."
ğŸ“Š Deneysel SonuÃ§lar ve Analiz
Modellerin baÅŸarÄ±sÄ±, eÄŸitim setinde gÃ¶rÃ¼lmeyen 41 adet AtCoder (Easy/Medium) problemi Ã¼zerinde test edilmiÅŸtir. BaÅŸarÄ± metriÄŸi olarak Pass@1 kullanÄ±lmÄ±ÅŸtÄ±r.
1. KarÅŸÄ±laÅŸtÄ±rmalÄ± Performans Tablosu
Model Mimarisi	Checkpoint (AdÄ±m)	Pass@1 Skoru	Ã‡Ã¶zÃ¼len Soru	Analiz Notu
Base Model (Ref)	-	~17.0%	7/41	Referans BaÅŸlangÄ±Ã§ NoktasÄ±
Deep Think	Step-400	%26.8	11/41	Maksimum Performans (GeÃ§ Zirve)
Deep Think	Step-700	%12.2	5/41	AÅŸÄ±rÄ± Overfitting (Ã‡Ã¶kÃ¼ÅŸ)
Diverse Think	Step-200	%24.4	10/41	HÄ±zlÄ± Ã–ÄŸrenme & Optimal Nokta
Diverse Think	Step-300	%14.6	6/41	Over-Reasoning KaynaklÄ± DÃ¼ÅŸÃ¼ÅŸ
Diverse Think	Step-400	%21.95	9/41	Doygunluk (Saturation)
(Tablo verileri proje raporundaki analizlere dayanmaktadÄ±r)
2. Kritik Analiz ve Bulgular (Analist Yorumu)
EÄŸitim sÃ¼reÃ§leri incelendiÄŸinde iki temel fenomen gÃ¶zlemlenmiÅŸtir:
ğŸ“‰ Deep Model: "GeÃ§ Ã–ÄŸrenme ve YÃ¼ksek Volatilite"
Deep stratejisi, en yÃ¼ksek skoruna (%26.8) eÄŸitimin ortalarÄ±nda (Step 400) ulaÅŸabilmiÅŸtir. Ancak Step 500 sonrasÄ±nda model ezberlemeye (overfitting) baÅŸlamÄ±ÅŸ ve performansÄ± %12.2'ye kadar gerilemiÅŸtir.
ğŸš€ Diverse Model: "Veri VerimliliÄŸi ve Erken Zirve"
Diverse modeli, eÄŸitimin henÃ¼z baÅŸÄ±nda (Step 200) %24.4 baÅŸarÄ± oranÄ±na ulaÅŸarak Deep modelinin baÅŸarÄ±sÄ±nÄ± yakalamÄ±ÅŸtÄ±r.
â€¢	Context Length Etkisi: 8192 tokenlÄ±k geniÅŸ baÄŸlam penceresi ve "Output" alanÄ±nÄ±n kullanÄ±mÄ± sayesinde model, Ã§ok az veriyle (Step 200) karmaÅŸÄ±k mantÄ±k yÃ¼rÃ¼tme yeteneÄŸi kazanmÄ±ÅŸtÄ±r.
â€¢	SonuÃ§: Diverse veri seti, 2 kat daha hÄ±zlÄ± Ã¶ÄŸrenme saÄŸlamÄ±ÅŸ ve kaynak verimliliÄŸi aÃ§Ä±sÄ±ndan Step 200final model olarak seÃ§ilmiÅŸtir.
ğŸ“ˆ GÃ¶rselleÅŸtirme
Performans DeÄŸiÅŸimi ve Optimal Noktalar
AÅŸaÄŸÄ±daki grafik, Deep modelin geÃ§ zirvesini ve Diverse modelin erken doygunluÄŸunu gÃ¶stermektedir:
ğŸš€ Kurulum ve Yeniden Ãœretilebilirlik
Projenin yerel ortamda tekrar edilmesi iÃ§in adÄ±mlar:
Bash
# 1. Repoyu KlonlayÄ±n
git clone https://github.com/KULLANICI_ADINIZ/LLM-Reasoning-LoRA.git
cd LLM-Reasoning-LoRA

# 2. Gereksinimleri YÃ¼kleyin
pip install -r requirements.txt

# 3. KlasÃ¶r YapÄ±sÄ±nÄ± DoÄŸrulayÄ±n
# CodeGen/models/ altÄ±nda "deep_instruction" ve "diverse_instruction" olmalÄ±dÄ±r.

# 4. Modeli Test Edin (Ã–rnek: Diverse Model)
python livecodebench_eval.py --model_type diverse_think --platform atcoder --difficulty easy
ğŸ“š KaynakÃ§a
Bu proje aÅŸaÄŸÄ±daki rehber ve veri setleri referans alÄ±narak geliÅŸtirilmiÅŸtir:
1.	Hugging Face LoRA Training Guide
2.	CodeGen Dataset (Deep & Diverse)
3.	LiveCodeBench Evaluation Framework


