ğŸ§  CodeGen: KÃ¼Ã§Ã¼k Ã–lÃ§ekli LLM'lerde Deep vs. Diverse DÃ¼ÅŸÃ¼nme Stratejileri
Bu proje, kÃ¼Ã§Ã¼k Ã¶lÃ§ekli BÃ¼yÃ¼k Dil Modellerinin (LLM) kod Ã¼retim yetenekleri Ã¼zerinde farklÄ± DÃ¼ÅŸÃ¼nce Zinciri (Chain-of-Thought - CoT) stratejilerinin etkisini araÅŸtÄ±rmaktadÄ±r. Qwen2.5-Coder-1.5B modeli, iki farklÄ± veri seti yapÄ±sÄ± kullanÄ±larak LoRA yÃ¶ntemiyle eÄŸitilmiÅŸ ve sonuÃ§lar karÅŸÄ±laÅŸtÄ±rÄ±lmÄ±ÅŸtÄ±r: Deep Think (AdÄ±m adÄ±m derinlemesine mantÄ±k) ve Diverse Think (Ã‡oklu Ã§Ã¶zÃ¼m perspektifleri).

ğŸ“Š Temel SonuÃ§lar
Deneylerimiz, 1.5B parametreli sÄ±nÄ±rlÄ± kapasiteye sahip modellerin, net ve yapÄ±landÄ±rÄ±lmÄ±ÅŸ bir dÃ¼ÅŸÃ¼nce zinciri (Deep Think) ile eÄŸitildiÄŸinde, Ã§eÅŸitlilik iÃ§eren stratejilere (Diverse Think) gÃ¶re daha hÄ±zlÄ± Ã¶ÄŸrendiÄŸini ve daha yÃ¼ksek performans gÃ¶sterdiÄŸini kanÄ±tlamÄ±ÅŸtÄ±r.

Model Varyasyonu	Strateji	Pass@1 Skoru	Ä°yileÅŸtirme
Base Model	EÄŸitimsiz (Zero-shot)	%2.44	-
Deep Think	AdÄ±m AdÄ±m MantÄ±k	%26.83	11 Kat ğŸš€
Diverse Think	Ã‡oklu BakÄ±ÅŸ AÃ§Ä±sÄ±	%24.39	10 Kat
Kritik Bulgular: Base modelin %2.44 olan baÅŸarÄ±sÄ±, Deep Think stratejisi ile %26.83'e yÃ¼kselmiÅŸtir. Bu, veri odaklÄ± ince ayarÄ±n (SFT) modelin kodlama yeteneÄŸini devasa oranda artÄ±rdÄ±ÄŸÄ±nÄ± gÃ¶sterir.

ğŸ› ï¸ Teknik Mimari ve AltyapÄ±
Proje, kaynak verimliliÄŸi ve optimizasyon gÃ¶zetilerek aÅŸaÄŸÄ±daki teknik altyapÄ± Ã¼zerine kurulmuÅŸtur:

Taban Model: Qwen/Qwen2.5-Coder-1.5B-Instruct (Decoder-Only Transformer)

EÄŸitim YÃ¶ntemi: LoRA (Low-Rank Adaptation)

Rank (r): 32

Alpha: 64

Learning Rate: 5e-5

Hedef ModÃ¼ller: q_proj, v_proj, gate_proj, up_proj, down_proj

Hassasiyet (Precision): bfloat16 (Mixed Precision)

Optimizer: AdamW (Cosine Scheduler ile)

BaÄŸlam UzunluÄŸu: 32k Token

ğŸ“ˆ Performans Analizi ve KarÅŸÄ±laÅŸtÄ±rma
1. Ã–ÄŸrenme EÄŸrisi (Deep vs. Diverse)

AÅŸaÄŸÄ±daki grafik, eÄŸitim sÃ¼reci boyunca modellerin HumanEval benchmark Ã¼zerindeki baÅŸarÄ±sÄ±nÄ± gÃ¶stermektedir. Deep Think (Mavi), eÄŸitimin baÅŸlarÄ±nda (Step 100) %17.1 gibi yÃ¼ksek bir seviyeye ulaÅŸarak kararlÄ± bir Ã¶ÄŸrenme sergilerken; Diverse Think (Turuncu), farklÄ± Ã§Ã¶zÃ¼m yollarÄ±nÄ± analiz etmenin getirdiÄŸi yÃ¼k nedeniyle daha yavaÅŸ bir baÅŸlangÄ±Ã§ yapmÄ±ÅŸtÄ±r.

(Not: KÄ±rmÄ±zÄ± kesikli Ã§izgi, Base Modelin %2.44'lÃ¼k baÅŸlangÄ±Ã§ seviyesini temsil eder.)

2. BaÅŸarÄ± ve BaÅŸarÄ±sÄ±zlÄ±k Analizi (Root Cause Analysis)

Benchmark sonuÃ§larÄ± incelendiÄŸinde modellerin davranÄ±ÅŸlarÄ± ÅŸu ÅŸekilde yorumlanmÄ±ÅŸtÄ±r:

âœ… Neden BaÅŸarÄ±lÄ± Oldular?

Deep Think: Problemi kodlamadan Ã¶nce <think> etiketleri iÃ§inde kÃ¼Ã§Ã¼k parÃ§alara ayÄ±rÄ±p planladÄ±ÄŸÄ± iÃ§in sÃ¶zdizimi ve mantÄ±k hatalarÄ±nÄ± minimize etmiÅŸtir.

Diverse Think: Standart dÃ¶ngÃ¼ler yerine Python'a Ã¶zgÃ¼ kÄ±sa yollarÄ± (list comprehension vb.) kullanarak daha yaratÄ±cÄ± Ã§Ã¶zÃ¼mler Ã¼retmiÅŸtir.

âŒ Neden BaÅŸarÄ±sÄ±z Oldular?

Deep Think HatasÄ± ("Over-reasoning"): Model bazen problemi analiz etmeye o kadar odaklanmÄ±ÅŸtÄ±r ki, Ã§Ã¶zÃ¼m kodunu yazarken baÄŸlam (context) sÄ±nÄ±rÄ±na takÄ±lmÄ±ÅŸ veya kod bloÄŸunu yarÄ±m bÄ±rakmÄ±ÅŸtÄ±r.

Diverse Think HatasÄ± ("Ambiguity"): EÄŸitim setinde aynÄ± soru iÃ§in birden fazla Ã§Ã¶zÃ¼m yolu olmasÄ±, modelde kararsÄ±zlÄ±k yaratmÄ±ÅŸtÄ±r. Model test sÄ±rasÄ±nda iki farklÄ± yÃ¶ntemi (Ã¶rneÄŸin recursive ve iterative) karÄ±ÅŸtÄ±rarak hibrit ve hatalÄ± kod Ã¼retmiÅŸtir.

3. SonuÃ§

BiliÅŸsel YÃ¼k Hipotezi: Analizler, 1.5B gibi kÃ¼Ã§Ã¼k modellerde, modele "tek ve net bir yol" (Deep Think) gÃ¶stermenin, ona "seÃ§enekler sunmaktan" (Diverse Think) Ã§ok daha verimli olduÄŸunu doÄŸrulamaktadÄ±r. Diverse stratejisi, daha bÃ¼yÃ¼k kapasiteli (7B+) modellerde potansiyel gÃ¶sterebilir ancak kÃ¼Ã§Ã¼k modellerde baÅŸlangÄ±Ã§ direncine (learning inertia) neden olmaktadÄ±r.

ğŸ“‚ Proje YapÄ±sÄ±
Bash
â”œâ”€â”€ result/               # Benchmark loglarÄ± (JSONL) ve analiz dosyalarÄ±
â”œâ”€â”€ src/                   # EÄŸitim (train.py) ve test (evaluate.py) kodlarÄ±
â”œâ”€â”€ assets/                # Performans grafikleri
â”œâ”€â”€ requirements.txt       # Gerekli kÃ¼tÃ¼phaneler
â””â”€â”€ README.md              # Proje dÃ¶kÃ¼mantasyonu
ğŸš€ Kurulum ve KullanÄ±m
1. Repoyu KlonlayÄ±n

Bash
git clone https://github.com/caglademir/CodeGen-Deep-vs-Diverse.git
cd CodeGen-Deep-vs-Diverse
2. KÃ¼tÃ¼phaneleri YÃ¼kleyin

Bash
pip install -r requirements.txt
3. Modeli EÄŸitin (Ã–rnek)

Deep Think veri seti ile eÄŸitimi baÅŸlatmak iÃ§in:

Bash
python src/train.py --model_id "Qwen/Qwen2.5-Coder-1.5B-Instruct" --dataset "deep-think" --epochs 3
4. Benchmark Testi

EÄŸitilen modeli HumanEval Ã¼zerinde test etmek iÃ§in:

Bash
python src/evaluate.py --checkpoint_path "models/deep_think/checkpoint-400"
ğŸ¤ KatkÄ±da Bulunma
KatkÄ±larÄ±nÄ±zÄ± bekliyoruz! LÃ¼tfen bir Pull Request gÃ¶ndermekten Ã§ekinmeyin.

ğŸ“œ Lisans
Bu proje Apache 2.0 LisansÄ± ile lisanslanmÄ±ÅŸtÄ±r.
